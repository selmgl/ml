{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction 4. Using Multiple Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Guillaume Lussier <lussier.guillaume@gmail.com>\n",
    "# base of work http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "# Date: Feb2017\n",
    "# ipython file, kernel 2.7, required modules: sklearn, numpy, pprint, time, logging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section8 : Mutiple Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multiple classifiers can be done several ways. One way is to chain them in what is called a pipeline.  \n",
    "An estimator pipeline will act as the addition of the estimators on the data.\n",
    "\n",
    "In the previous works we have chained a vectorizer with a classifier. The vectorizers we used were a simple count vectorizer and a tf-idf vectorizer. The classifiers were Logistic Regression, multinomial Naive Bayes.\n",
    "\n",
    "One of the difficulties of using several estimators is to chose the different parameters to be used with each of them, especially as one can impact the result of the next one. The sklearn GridSearchCV library can help with identifying the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1 Introduction of the libraries, description of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn data set\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# sklearn text feature extraction pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# basic libraries\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "# this is to configure python logging to handle warning messages \n",
    "import logging\n",
    "logging.basicConfig()\n",
    "\n",
    "\n",
    "# TfidfVectorizer\n",
    "# tf / term frequency\n",
    "# idf / inverse documentfrequency\n",
    "# max_df: terms with a frequency higher than this value are ignored\n",
    "# min_df: cut-off, terms wih an obsolute count lower than this value are ignored\n",
    "# analyzer='word': default value, feature will be made of words n-grams\n",
    "# ngram_range=tuple (min_n, max_n): default 1, n-grams used such as min_n <= n <= max_n\n",
    "# vocabulary: default None, if not given, a vocabulary is determined from the input documents.\n",
    "# max_features: default None, if not None, build a vocabulary with only top max_features ordered by term frequency across the corpus.\n",
    "# stop_words: None, english\n",
    "# example : TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "# note: the effect of the different parameters on the tf-idf vectorizer & fit have been discussed in fextraction2 \n",
    "\n",
    "# LogisticRegression\n",
    "# penalty: str, ‘l1’ or ‘l2’, default: ‘l2’\n",
    "# C: float, default: 1.0, smaller values specify stronger regularization\n",
    "# fit_intercept : bool, default: True, constant (a.k.a. bias or intercept) added to the decision function\n",
    "# random_state : int seed, RandomState instance, default: None, seed of the pseudo random number generator to use when shuffling the data\n",
    "# solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’}, default: ‘liblinear’\n",
    "# n_jobs : int, default: 1, Number of CPU cores used during cross-validation loop. If -1, all cores are used\n",
    "# example : LogisticRegression(random_state=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
