{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction 4. Using Multiple Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Guillaume Lussier <lussier.guillaume@gmail.com>\n",
    "# base of work http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "# Date: Feb2017\n",
    "# ipython file, kernel 2.7, required modules: sklearn, numpy, pprint, time, logging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section8 : Pipeline of Mutiple Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multiple classifiers can be done several ways. One way is to chain them in what is called a pipeline.  \n",
    "An estimator pipeline will act as the addition of the estimators on the data.\n",
    "\n",
    "In the previous works we have chained a vectorizer with a classifier. The vectorizers we used were a simple count vectorizer and a tf-idf vectorizer. The classifiers were Logistic Regression, multinomial Naive Bayes.\n",
    "\n",
    "One of the difficulties of using several estimators is to chose the different parameters to be used with each of them, especially as one can impact the result of the next one. The sklearn GridSearchCV library can help with identifying the best parameters.\n",
    "\n",
    "An example with CountVectorizer, TfidfTransformer, SGDClassifier and a pipeline can be found here:\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py  \n",
    "Below we continue to work on the basis and results obtained in our previous work (fextraction1, 2 and 3). We will use TfidfVectorizer and LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction of the libraries, description of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sklearn data set\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# sklearn text feature extraction pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# basic libraries\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "# this is to configure python logging to handle warning messages \n",
    "import logging\n",
    "logging.basicConfig()\n",
    "\n",
    "\n",
    "# TfidfVectorizer\n",
    "# tf / term frequency\n",
    "# idf / inverse documentfrequency\n",
    "# max_df: terms with a frequency higher than this value are ignored\n",
    "# min_df: cut-off, terms wih an obsolute count lower than this value are ignored\n",
    "# analyzer='word': default value, feature will be made of words n-grams\n",
    "# ngram_range=tuple (min_n, max_n): default 1, n-grams used such as min_n <= n <= max_n\n",
    "# vocabulary: default None, if not given, a vocabulary is determined from the input documents.\n",
    "# max_features: default None, if not None, build a vocabulary with only top max_features ordered by term frequency across the corpus.\n",
    "# stop_words: None, english\n",
    "# example : TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "# note: the effect of the different parameters on the tf-idf vectorizer & fit have been discussed in fextraction2 \n",
    "\n",
    "# LogisticRegression\n",
    "# penalty: str, ‘l1’ or ‘l2’, default: ‘l2’\n",
    "# C: float, default: 1.0, positive float, smaller values specify stronger regularization\n",
    "# fit_intercept : bool, default: True, constant (a.k.a. bias or intercept) added to the decision function\n",
    "# random_state : int seed, RandomState instance, default: None, seed of the pseudo random number generator to use when shuffling the data\n",
    "# solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’}, default: ‘liblinear’\n",
    "# n_jobs : int, default: 1, Number of CPU cores used during cross-validation loop. If -1, all cores are used\n",
    "# example : LogisticRegression(random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the search parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['comp.graphics', 'sci.crypt', 'sci.space', 'talk.religion.misc']\n",
      "Data loaded from 20 newsgroups:\n",
      "2149 documents\n",
      "4 categories\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    'comp.graphics',\n",
    "    'sci.crypt',\n",
    "    'sci.space',\n",
    "    'talk.religion.misc',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "#categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "# fetching 20newsgroups data set with filtering of the header/footers/quotes to be more realistic\n",
    "data = fetch_20newsgroups(subset='train', shuffle=True, random_state=1, \n",
    "                          remove=('headers', 'footers', 'quotes'),\n",
    "                          categories=categories)\n",
    "\n",
    "print(\"Data loaded from 20 newsgroups:\")\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the piepline and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer()), # we use a TfidfVectorizer so the CountVectorizer is not needed\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    #'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__max_df': (0.5, 0.75, 0.95), # max frequence of word for it to be kept as a feature\n",
    "    'tfidf__min_df': (2, 10, 50), # minimum number of word occurrences for it to be kept as a feature\n",
    "    'tfidf__max_features': (2000, 20000, 50000), # max number of features in the model\n",
    "    # stop_words = 'english' will not be used here as it render max_df impact less visible\n",
    "    'logreg__C': (0.1, 0.5, 1.0), # smaller values specify stronger regularization\n",
    "    'logreg__fit_intercept': (True, False), # bias constant should be added to the decision function\n",
    "    'logreg__solver': ('liblinear', 'sag'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution of the pipeline and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "('pipeline:', ['tfidf', 'logreg'])\n",
      "parameters:\n",
      "{'logreg__C': (0.1, 0.5, 1.0),\n",
      " 'logreg__fit_intercept': (True, False),\n",
      " 'logreg__solver': ('liblinear', 'sag'),\n",
      " 'tfidf__max_df': (0.5, 0.75, 0.95),\n",
      " 'tfidf__max_features': (2000, 20000, 50000),\n",
      " 'tfidf__min_df': (2, 10, 50)}\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 573.207s\n",
      "()\n",
      "Best score: 0.863\n",
      "Best parameters set:\n",
      "\tlogreg__C: 1.0\n",
      "\tlogreg__fit_intercept: False\n",
      "\tlogreg__solver: 'liblinear'\n",
      "\ttfidf__max_df: 0.5\n",
      "\ttfidf__max_features: 20000\n",
      "\ttfidf__min_df: 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(data.data, data.target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Performing grid search...\n",
    "('pipeline:', ['tfidf', 'logreg'])\n",
    "parameters:\n",
    "{'logreg__C': (0.1, 0.5, 1.0),\n",
    " 'logreg__fit_intercept': (True, False),\n",
    " 'logreg__solver': ('liblinear', 'sag'),\n",
    " 'tfidf__max_df': (0.5, 0.75, 0.95),\n",
    " 'tfidf__max_features': (2000, 20000, 50000),\n",
    " 'tfidf__min_df': (2, 10, 50)}\n",
    "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.6s\n",
    "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.9min\n",
    "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.4min\n",
    "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  7.8min\n",
    "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:  9.5min finished\n",
    "done in 573.207s\n",
    "()\n",
    "Best score: 0.863\n",
    "Best parameters set:\n",
    "\tlogreg__C: 1.0\n",
    "\tlogreg__fit_intercept: False\n",
    "\tlogreg__solver: 'liblinear'\n",
    "\ttfidf__max_df: 0.5\n",
    "\ttfidf__max_features: 20000\n",
    "\ttfidf__min_df: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-6f92b8f2cdbb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-6f92b8f2cdbb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Performing grid search...\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Performing grid search...\n",
    "('pipeline:', ['tfidf', 'logreg'])\n",
    "parameters:\n",
    "{'logreg__C': (0.1, 0.5, 1.0),\n",
    " 'logreg__fit_intercept': (True, False),\n",
    " 'logreg__solver': ('liblinear', 'sag'),\n",
    " 'tfidf__max_df': (0.5, 0.75, 0.95),\n",
    " 'tfidf__max_features': (2000, 20000, 50000),\n",
    " 'tfidf__min_df': (2, 10, 50)}\n",
    "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.6s\n",
    "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.9min\n",
    "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.4min\n",
    "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  7.8min\n",
    "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:  9.5min finished\n",
    "done in 573.207s\n",
    "()\n",
    "Best score: 0.863\n",
    "Best parameters set:\n",
    "\tlogreg__C: 1.0\n",
    "\tlogreg__fit_intercept: False\n",
    "\tlogreg__solver: 'liblinear'\n",
    "\ttfidf__max_df: 0.5\n",
    "\ttfidf__max_features: 20000\n",
    "\ttfidf__min_df: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the result tell us ?\n",
    "\n",
    "TF-IDF Vectorizer  \n",
    "1. min_df = 2: this is aligned with removing as little as possible of the features\n",
    "2. max_df = 50%: this is the strongest filtering of the most common words, focusing a category on its specific words\n",
    "3. max_features = 20000: as we have about 30K features, this is aligned with the results we had in the previous trials were we have seen that limiting the features to 2000 was too strong (and did not improve runtime as much as could be expected)\n",
    "\n",
    "Log Reg Classifier  \n",
    "1. C = 1.0: no regularization works best here, this can depend on the data provided\n",
    "2. fit_intercept = False: no bias \n",
    "3. solver = liblinear: the dataset is small enough for the liblinear to work better than sag, this would change with a much larger dataset\n",
    "\n",
    "In the end, for our dataset the pipeline indicates us that we need to use as many features as possible (not remove rare words too strongly) and ignore the most common features (ideal here is to use the stop_words for english, or a very strong max_df.  \n",
    "This is very close to the results we observed when changing paremeters of the tf-idf and logistic regression in the previous works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section9 : Pipeline Refining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us refine the results of the first pipeline obtained in Section8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.3, 0.4, 0.5), # max frequence of word for it to be kept as a feature\n",
    "    'tfidf__max_features': (20000, 30000, 40000), # max number of features in the model \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parameter values for parameter (logreg__C) need to be a sequence(but not a string) or np.ndarray.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ffb4194a2468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;31m# find the best parameters for both the feature extraction and the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[1;31m# classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Performing grid search...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\glussier\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, param_grid, scoring, fit_params, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[1;32m    923\u001b[0m             return_train_score=return_train_score)\n\u001b[1;32m    924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         \u001b[0m_check_param_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\glussier\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 raise ValueError(\"Parameter values for parameter ({0}) need \"\n\u001b[1;32m    341\u001b[0m                                  \u001b[1;34m\"to be a sequence(but not a string) or\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                  \" np.ndarray.\".format(name))\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter values for parameter (logreg__C) need to be a sequence(but not a string) or np.ndarray."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(data.data, data.target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing grid search...\n",
    "('pipeline:', ['tfidf', 'logreg'])\n",
    "parameters:\n",
    "{'tfidf__max_df': (0.3, 0.4, 0.5),\n",
    " 'tfidf__max_features': (20000, 30000, 40000)}\n",
    "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   21.5s finished\n",
    "done in 23.177s\n",
    "()\n",
    "Best score: 0.858\n",
    "Best parameters set:\n",
    "\ttfidf__max_df: 0.3\n",
    "\ttfidf__max_features: 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Performing grid search...\n",
    "('pipeline:', ['tfidf', 'logreg'])\n",
    "parameters:\n",
    "{'tfidf__max_df': (0.3, 0.4, 0.5),\n",
    " 'tfidf__max_features': (20000, 30000, 40000)}\n",
    "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   21.5s finished\n",
    "done in 23.177s\n",
    "()\n",
    "Best score: 0.858\n",
    "Best parameters set:\n",
    "\ttfidf__max_df: 0.3\n",
    "\ttfidf__max_features: 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly these refinement results show that filtering even more commong words by removing any word present in more than 30% of the data brings the best score of the pipeline."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
